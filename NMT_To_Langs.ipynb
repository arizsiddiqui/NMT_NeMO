{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b798ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE! Installing ujson may make loading annotations faster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-03-15 18:17:35 experimental:27] Module <class 'nemo.collections.nlp.data.text_normalization.decoder_dataset.TextNormalizationDecoderDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-03-15 18:17:35 experimental:27] Module <class 'nemo.collections.nlp.data.text_normalization.tagger_dataset.TextNormalizationTaggerDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-03-15 18:17:35 experimental:27] Module <class 'nemo.collections.nlp.data.text_normalization.test_dataset.TextNormalizationTestDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "[NeMo W 2022-03-15 18:17:36 experimental:27] Module <class 'nemo.collections.nlp.models.duplex_text_normalization.duplex_decoder.DuplexDecoderModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-03-15 18:17:36 experimental:27] Module <class 'nemo.collections.nlp.models.duplex_text_normalization.duplex_tagger.DuplexTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-03-15 18:17:36 experimental:27] Module <class 'nemo.collections.nlp.models.duplex_text_normalization.duplex_tn.DuplexTextNormalizationModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-03-15 18:17:36 cloud:56] Found existing object /root/.cache/torch/NeMo/NeMo_1.5.0/en_de_24x6/6c5b7c17d3f21e44d371a70cbd573f54/en_de_24x6.nemo.\n",
      "[NeMo I 2022-03-15 18:17:36 cloud:62] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.5.0/en_de_24x6/6c5b7c17d3f21e44d371a70cbd573f54/en_de_24x6.nemo\n",
      "[NeMo I 2022-03-15 18:17:36 common:728] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-03-15 18:17:56 tokenizer_utils:163] Getting YouTokenToMeTokenizer with model: /tmp/tmpl5_j1n2d/0f956fde1f684ec2840d5521d4ef02d8_shared_tokenizer.32000.BPE.model with r2l: False.\n",
      "[NeMo I 2022-03-15 18:17:56 tokenizer_utils:163] Getting YouTokenToMeTokenizer with model: /tmp/tmpl5_j1n2d/441eb304d4c94a3da270598fba65c4ab_shared_tokenizer.32000.BPE.model with r2l: False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-03-15 18:17:57 modelPT:130] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    src_file_name: null\n",
      "    tgt_file_name: null\n",
      "    use_tarred_dataset: true\n",
      "    tar_files: /data/tarred_dataset_4k_tokens/parallel.batches.tokens.4000._OP_0..6280_CL_.tar\n",
      "    metadata_file: /data/tarred_dataset_4k_tokens/metadata.tokens.4000.json\n",
      "    lines_per_dataset_fragment: 1000000\n",
      "    num_batches_per_tarfile: 100\n",
      "    shard_strategy: scatter\n",
      "    tokens_in_batch: 512\n",
      "    clean: true\n",
      "    max_seq_length: 512\n",
      "    min_seq_length: 1\n",
      "    cache_ids: false\n",
      "    cache_data_per_node: false\n",
      "    use_cache: false\n",
      "    shuffle: true\n",
      "    num_samples: -1\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    num_workers: 8\n",
      "    reverse_lang_direction: false\n",
      "    load_from_tarred_dataset: false\n",
      "    metadata_path: null\n",
      "    tar_shuffle_n: 100\n",
      "    n_preproc_jobs: -2\n",
      "    tar_file_prefix: parallel\n",
      "    concat_sampling_technique: temperature\n",
      "    concat_sampling_temperature: 5\n",
      "    concat_sampling_probabilities: null\n",
      "    \n",
      "[NeMo W 2022-03-15 18:17:57 modelPT:137] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    src_file_name:\n",
      "    - /data/newstest2020-en-de.clean.tok.src\n",
      "    - /data/newstest2019-en-de.clean.tok.src\n",
      "    - /data/newstest2018-en-de.clean.tok.src\n",
      "    - /data/newstest2014-en-de.clean.tok.src\n",
      "    tgt_file_name:\n",
      "    - /data/newstest2020-en-de.clean.tok.ref\n",
      "    - /data/newstest2019-en-de.clean.tok.ref\n",
      "    - /data/newstest2018-en-de.clean.tok.ref\n",
      "    - /data/newstest2014-en-de.clean.tok.ref\n",
      "    use_tarred_dataset: false\n",
      "    tar_files: null\n",
      "    metadata_file: null\n",
      "    lines_per_dataset_fragment: 1000000\n",
      "    num_batches_per_tarfile: 1000\n",
      "    shard_strategy: scatter\n",
      "    tokens_in_batch: 512\n",
      "    clean: false\n",
      "    max_seq_length: 512\n",
      "    min_seq_length: 1\n",
      "    cache_ids: false\n",
      "    cache_data_per_node: false\n",
      "    use_cache: false\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    num_workers: 8\n",
      "    reverse_lang_direction: false\n",
      "    load_from_tarred_dataset: false\n",
      "    metadata_path: null\n",
      "    tar_shuffle_n: 100\n",
      "    n_preproc_jobs: -2\n",
      "    tar_file_prefix: parallel\n",
      "    concat_sampling_technique: temperature\n",
      "    concat_sampling_temperature: 5\n",
      "    concat_sampling_probabilities: null\n",
      "    \n",
      "[NeMo W 2022-03-15 18:17:57 modelPT:143] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    src_file_name: /data/newstest2020-en-de.clean.tok.src\n",
      "    tgt_file_name: /data/newstest2020-en-de.clean.tok.ref\n",
      "    use_tarred_dataset: false\n",
      "    tar_files: null\n",
      "    metadata_file: null\n",
      "    lines_per_dataset_fragment: 1000000\n",
      "    num_batches_per_tarfile: 1000\n",
      "    shard_strategy: scatter\n",
      "    tokens_in_batch: 512\n",
      "    clean: false\n",
      "    max_seq_length: 512\n",
      "    min_seq_length: 1\n",
      "    cache_ids: false\n",
      "    cache_data_per_node: false\n",
      "    use_cache: false\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    num_workers: 8\n",
      "    reverse_lang_direction: false\n",
      "    load_from_tarred_dataset: false\n",
      "    metadata_path: null\n",
      "    tar_shuffle_n: 100\n",
      "    n_preproc_jobs: -2\n",
      "    tar_file_prefix: parallel\n",
      "    concat_sampling_technique: temperature\n",
      "    concat_sampling_temperature: 5\n",
      "    concat_sampling_probabilities: null\n",
      "    \n",
      "[NeMo W 2022-03-15 18:17:57 modelPT:1079] World size can only be set by PyTorch Lightning Trainer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-03-15 18:18:09 save_restore_connector:149] Model MTEncDecModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.5.0/en_de_24x6/6c5b7c17d3f21e44d371a70cbd573f54/en_de_24x6.nemo.\n"
     ]
    }
   ],
   "source": [
    "from nemo.collections.nlp.models import MTEncDecModel\n",
    "\n",
    "MTEncDecModel.list_available_models()\n",
    "\n",
    "# model_fr = MTEncDecModel.from_pretrained(\"nmt_en_fr_transformer24x6\")\n",
    "# model_es = MTEncDecModel.from_pretrained(\"nmt_en_es_transformer24x6\")\n",
    "# model_ru = MTEncDecModel.from_pretrained(\"nmt_en_ru_transformer24x6\")\n",
    "# model_zh = MTEncDecModel.from_pretrained(\"nmt_en_zh_transformer24x6\")\n",
    "model_de = MTEncDecModel.from_pretrained(\"nmt_en_de_transformer24x6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49dc18ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-03-15 18:18:11 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/nemo/collections/nlp/modules/common/transformer/transformer_generators.py:363: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "      mems_ids = indices_i.unsqueeze(2).unsqueeze(3).repeat(1, 1, p_len - 1, hidden_size) // self.beam_size\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hallo zusammen!']\n"
     ]
    }
   ],
   "source": [
    "# translations_fr = model_fr.translate([\"Hello!\"], source_lang=\"en\", target_lang=\"fr\")\n",
    "# translations_es = model_es.translate([\"Hello!\"], source_lang=\"en\", target_lang=\"es\")\n",
    "# translations_ru = model_ru.translate([\"Hello!\"], source_lang=\"en\", target_lang=\"ru\")\n",
    "# translations_zh = model_zh.translate([\"Hello!\"], source_lang=\"en\", target_lang=\"zh\")\n",
    "translations_de = model_de.translate([\"Hello!\"], source_lang=\"en\", target_lang=\"de\")\n",
    "\n",
    "# print(translations_fr, translations_es ,sep='\\n')\n",
    "# print(translations_ru, translations_zh ,sep='\\n')\n",
    "print(translations_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c04880",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = open(\"source_en.txt\", \"r\")\n",
    "text = [line for line in reader.readlines()]\n",
    "reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff8e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translations_fr = model_fr.translate(text, source_lang=\"en\", target_lang=\"fr\")\n",
    "# translations_es = model_es.translate(text, source_lang=\"en\", target_lang=\"es\")\n",
    "# translations_ru = model_ru.translate(text, source_lang=\"en\", target_lang=\"ru\")\n",
    "# translations_zh = model_zh.translate(text, source_lang=\"en\", target_lang=\"zh\")\n",
    "translations_de = model_de.translate(text, source_lang=\"en\", target_lang=\"de\")\n",
    "\n",
    "# writer_fr = open(\"result_fr.txt\", \"w\")\n",
    "# writer_es = open(\"result_es.txt\", \"w\")\n",
    "# writer_ru = open(\"result_ru.txt\", \"w\")\n",
    "# writer_zh = open(\"result_zh.txt\", \"w\")\n",
    "writer_de = open(\"result_de.txt\", \"w\")\n",
    "\n",
    "# for line in translations_fr:\n",
    "#     writer_fr.write(line+'\\n')\n",
    "# writer_fr.close()\n",
    "\n",
    "# for line in translations_es:\n",
    "#     writer_es.write(line+'\\n')\n",
    "# writer_es.close()\n",
    "\n",
    "# for line in translations_ru:\n",
    "#     writer_ru.write(line+'\\n')\n",
    "# writer_ru.close()\n",
    "\n",
    "# for line in translations_zh:\n",
    "#     writer_zh.write(line+'\\n')\n",
    "# writer_zh.close()\n",
    "\n",
    "for line in translations_de:\n",
    "    writer_de.write(line+'\\n')\n",
    "writer_de.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58de25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
